{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.transform import rescale\n",
    "import skimage.color as color\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.external import tifffile\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D,GlobalAveragePooling2D,Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,Model, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.applications import ResNet50, VGG16, MobileNet, Xception, DenseNet121\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.backend import clear_session\n",
    "\n",
    "## Image Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import argparse\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "INPUT_SHAPE = (128, 128, 3) # Image Dimensions\n",
    "BATCH_SIZE = 128\n",
    "DROPOUT_RATE = 0.5\n",
    "EPOCHS = 25\n",
    "LR = 0.0001 # Learning Rate\n",
    "REG_STRENGTH = 0.01 # Regularization Strength\n",
    "NFOLDS = 5 # No of folds for cross validation\n",
    "WORKERS = 4 # Multithreading no of threads\n",
    "MAXQ = 10 # Max Queue size for multithreading\n",
    "THRES = [0.2] * 17 # Threshold for truth value of label, applied on sigmoid output.\n",
    "\n",
    "TRAIN_PATH = 'data/train-jpg-haze'\n",
    "TEST_PATH = 'data/test-jpg-haze'\n",
    "\n",
    "TRAIN_CSV_PATH = 'data/train_v2.csv'\n",
    "TEST_CSV_PATH = 'data/sample_submission_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_name                                       tags\n",
      "0  train_0.jpg                               haze primary\n",
      "1  train_1.jpg            agriculture clear primary water\n",
      "2  train_2.jpg                              clear primary\n",
      "3  train_3.jpg                              clear primary\n",
      "4  train_4.jpg  agriculture clear habitation primary road\n",
      "\n",
      "   image_name                                        tags\n",
      "0  test_0.jpg  [primary, clear, agriculture, road, water]\n",
      "1  test_1.jpg  [primary, clear, agriculture, road, water]\n",
      "2  test_2.jpg  [primary, clear, agriculture, road, water]\n",
      "3  test_3.jpg  [primary, clear, agriculture, road, water]\n",
      "4  test_4.jpg  [primary, clear, agriculture, road, water]\n"
     ]
    }
   ],
   "source": [
    "# Construct dataframes holding training and test data information\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "df_train['image_name'] = df_train['image_name'].astype(str) + '.jpg'\n",
    "df_test['image_name'] = df_test['image_name'].astype(str) + '.jpg'\n",
    "\n",
    "df_test['tags'] = df_test['tags'].apply(lambda x: x.split(' '))\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61191, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40479, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files are numpy Arrays with shape Nx1\n",
    "X_train_files = np.array(df_train['image_name'].tolist())\n",
    "X_train_files.reshape((X_train_files.shape[0], 1))\n",
    "y_train = np.array(df_train['tags'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agriculture', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'clear', 'cloudy', 'conventional_mine', 'cultivation', 'habitation', 'haze', 'partly_cloudy', 'primary', 'road', 'selective_logging', 'slash_burn', 'water']\n"
     ]
    }
   ],
   "source": [
    "# There are 17 Labels and each image is tagged with multiple labels\n",
    "# Lets print out the unique label list\n",
    "\n",
    "labels = []\n",
    "\n",
    "for tag in df_train['tags'].values:\n",
    "    labels_in_tag = tag.split(' ')\n",
    "    for label in labels_in_tag:\n",
    "        if label not in labels:\n",
    "            labels.append(label)\n",
    "        \n",
    "labels.sort()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventional_mine is tagged least no of times: 99\n",
      "primary is tagged max no of times: 37512\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distribution of the labels :\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "labels_count = {}\n",
    "\n",
    "for tag in df_train['tags'].values:\n",
    "    labels_in_tag = tag.split(' ')\n",
    "    for label in labels_in_tag:\n",
    "        if label in labels_count:\n",
    "            labels_count[label] += 1\n",
    "        else:\n",
    "            labels_count[label] = 0\n",
    "            \n",
    "min_label = min(labels_count, key=labels_count.get)\n",
    "max_label = max(labels_count, key=labels_count.get)\n",
    "\n",
    "print(min_label+\" is tagged least no of times: \"+str(labels_count[min_label]))\n",
    "print(max_label+\" is tagged max no of times: \"+str(labels_count[max_label]))\n",
    "            \n",
    "plt.bar(range(len(labels_count)), list(labels_count.values()), align='center')\n",
    "plt.xticks(range(len(labels_count)), list(labels_count.keys()), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 129, 129, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 3,362,257\n",
      "Trainable params: 3,340,369\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Define MobileNet model for Haze removal\n",
    "def create_model():\n",
    "    img = Input(shape = (128, 128, 3))\n",
    "    model_mob = MobileNet(include_top=False, weights='imagenet', input_tensor=img, input_shape=None, pooling='avg')\n",
    "\n",
    "    final_layer = model_mob.layers[-1].output\n",
    "    dense_layer_1 = Dense(128, activation = 'relu')(final_layer)\n",
    "    output_layer = Dense(17, activation = 'sigmoid')(dense_layer_1)\n",
    "\n",
    "    model = Model(input = model_mob.input, output = output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model evaluation metric : F2 Beta score:\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = y_true * y_pred\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f_score = tf.where(tf.math.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32383 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n",
      "Found 61191 validated image filenames belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 195s 772ms/step - loss: 0.1707 - f2_score: 0.8100 - val_loss: 0.1272 - val_f2_score: 0.8371\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 180s 711ms/step - loss: 0.1159 - f2_score: 0.8640 - val_loss: 0.1130 - val_f2_score: 0.8736\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 180s 710ms/step - loss: 0.1081 - f2_score: 0.8733 - val_loss: 0.0812 - val_f2_score: 0.8742\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 180s 713ms/step - loss: 0.1033 - f2_score: 0.8786 - val_loss: 0.1982 - val_f2_score: 0.8839\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 180s 713ms/step - loss: 0.1001 - f2_score: 0.8818 - val_loss: 0.0998 - val_f2_score: 0.8768\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0974 - f2_score: 0.8856 - val_loss: 0.0860 - val_f2_score: 0.8874\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0951 - f2_score: 0.8883 - val_loss: 0.0703 - val_f2_score: 0.8884\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0937 - f2_score: 0.8890 - val_loss: 0.0816 - val_f2_score: 0.8874\n",
      "Epoch 9/25\n",
      "253/253 [==============================] - 180s 713ms/step - loss: 0.0921 - f2_score: 0.8917 - val_loss: 0.0481 - val_f2_score: 0.8887\n",
      "Epoch 10/25\n",
      "253/253 [==============================] - 181s 714ms/step - loss: 0.0899 - f2_score: 0.8941 - val_loss: 0.0928 - val_f2_score: 0.8903\n",
      "Epoch 11/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0888 - f2_score: 0.8950 - val_loss: 0.1078 - val_f2_score: 0.8888\n",
      "Epoch 12/25\n",
      "253/253 [==============================] - 181s 714ms/step - loss: 0.0874 - f2_score: 0.8974 - val_loss: 0.0781 - val_f2_score: 0.8956\n",
      "Epoch 13/25\n",
      "253/253 [==============================] - 181s 714ms/step - loss: 0.0859 - f2_score: 0.8984 - val_loss: 0.0986 - val_f2_score: 0.8936\n",
      "Epoch 14/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0845 - f2_score: 0.9005 - val_loss: 0.1362 - val_f2_score: 0.8848\n",
      "Epoch 15/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0834 - f2_score: 0.9024 - val_loss: 0.0693 - val_f2_score: 0.8888\n",
      "Epoch 16/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0820 - f2_score: 0.9040 - val_loss: 0.0447 - val_f2_score: 0.8904\n",
      "Epoch 17/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0805 - f2_score: 0.9055 - val_loss: 0.0920 - val_f2_score: 0.8950\n",
      "Epoch 18/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0788 - f2_score: 0.9074 - val_loss: 0.1241 - val_f2_score: 0.8919\n",
      "Epoch 19/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0772 - f2_score: 0.9088 - val_loss: 0.0611 - val_f2_score: 0.8900\n",
      "Epoch 20/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0762 - f2_score: 0.9106 - val_loss: 0.0927 - val_f2_score: 0.8881\n",
      "Epoch 21/25\n",
      "253/253 [==============================] - 181s 714ms/step - loss: 0.0749 - f2_score: 0.9120 - val_loss: 0.1243 - val_f2_score: 0.8970\n",
      "Epoch 22/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0737 - f2_score: 0.9130 - val_loss: 0.1125 - val_f2_score: 0.8948\n",
      "Epoch 23/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0727 - f2_score: 0.9141 - val_loss: 0.1057 - val_f2_score: 0.8871\n",
      "Epoch 24/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0712 - f2_score: 0.9155 - val_loss: 0.0885 - val_f2_score: 0.8948\n",
      "Epoch 25/25\n",
      "253/253 [==============================] - 181s 714ms/step - loss: 0.0698 - f2_score: 0.9172 - val_loss: 0.0744 - val_f2_score: 0.8973\n",
      "Found 32383 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n",
      "Found 61191 validated image filenames belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 193s 763ms/step - loss: 0.1844 - f2_score: 0.8043 - val_loss: 0.0780 - val_f2_score: 0.8415\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.1157 - f2_score: 0.8635 - val_loss: 0.1204 - val_f2_score: 0.8756\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.1074 - f2_score: 0.8736 - val_loss: 0.0862 - val_f2_score: 0.8832\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.1034 - f2_score: 0.8792 - val_loss: 0.0693 - val_f2_score: 0.8821\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0995 - f2_score: 0.8828 - val_loss: 0.1194 - val_f2_score: 0.8839\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0974 - f2_score: 0.8856 - val_loss: 0.0752 - val_f2_score: 0.8858\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0955 - f2_score: 0.8878 - val_loss: 0.1449 - val_f2_score: 0.8950\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0933 - f2_score: 0.8910 - val_loss: 0.1056 - val_f2_score: 0.8857\n",
      "Epoch 9/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0913 - f2_score: 0.8938 - val_loss: 0.0909 - val_f2_score: 0.8933\n",
      "Epoch 10/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0897 - f2_score: 0.8949 - val_loss: 0.1010 - val_f2_score: 0.8909\n",
      "Epoch 11/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0884 - f2_score: 0.8961 - val_loss: 0.0780 - val_f2_score: 0.8882\n",
      "Epoch 12/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0865 - f2_score: 0.8991 - val_loss: 0.1018 - val_f2_score: 0.8947\n",
      "Epoch 13/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0858 - f2_score: 0.8984 - val_loss: 0.0826 - val_f2_score: 0.8923\n",
      "Epoch 14/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0843 - f2_score: 0.9004 - val_loss: 0.1086 - val_f2_score: 0.8958\n",
      "Epoch 15/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0827 - f2_score: 0.9035 - val_loss: 0.0859 - val_f2_score: 0.8984\n",
      "Epoch 16/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0818 - f2_score: 0.9033 - val_loss: 0.1033 - val_f2_score: 0.8961\n",
      "Epoch 17/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0806 - f2_score: 0.9055 - val_loss: 0.0664 - val_f2_score: 0.8961\n",
      "Epoch 18/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0789 - f2_score: 0.9068 - val_loss: 0.1455 - val_f2_score: 0.8919\n",
      "Epoch 19/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0771 - f2_score: 0.9092 - val_loss: 0.1213 - val_f2_score: 0.8918\n",
      "Epoch 20/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0760 - f2_score: 0.9106 - val_loss: 0.0740 - val_f2_score: 0.8949\n",
      "Epoch 21/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0743 - f2_score: 0.9129 - val_loss: 0.0685 - val_f2_score: 0.8914\n",
      "Epoch 22/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0737 - f2_score: 0.9130 - val_loss: 0.1523 - val_f2_score: 0.8931\n",
      "Epoch 23/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0724 - f2_score: 0.9147 - val_loss: 0.1017 - val_f2_score: 0.8889\n",
      "Epoch 24/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0710 - f2_score: 0.9159 - val_loss: 0.1202 - val_f2_score: 0.8895\n",
      "Epoch 25/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0691 - f2_score: 0.9187 - val_loss: 0.0811 - val_f2_score: 0.8907\n",
      "Found 32383 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n",
      "Found 61191 validated image filenames belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 192s 759ms/step - loss: 0.1856 - f2_score: 0.7998 - val_loss: 0.1964 - val_f2_score: 0.8349\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.1151 - f2_score: 0.8645 - val_loss: 0.1078 - val_f2_score: 0.8697\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.1077 - f2_score: 0.8732 - val_loss: 0.0819 - val_f2_score: 0.8815\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.1021 - f2_score: 0.8803 - val_loss: 0.0744 - val_f2_score: 0.8837\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 180s 713ms/step - loss: 0.1001 - f2_score: 0.8828 - val_loss: 0.0932 - val_f2_score: 0.8893\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 181s 715ms/step - loss: 0.0973 - f2_score: 0.8864 - val_loss: 0.0691 - val_f2_score: 0.8870\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0950 - f2_score: 0.8883 - val_loss: 0.0809 - val_f2_score: 0.8868\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0931 - f2_score: 0.8905 - val_loss: 0.0858 - val_f2_score: 0.8942\n",
      "Epoch 9/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0909 - f2_score: 0.8941 - val_loss: 0.0756 - val_f2_score: 0.8898\n",
      "Epoch 10/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0904 - f2_score: 0.8931 - val_loss: 0.0842 - val_f2_score: 0.8934\n",
      "Epoch 11/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0877 - f2_score: 0.8973 - val_loss: 0.1312 - val_f2_score: 0.8897\n",
      "Epoch 12/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0871 - f2_score: 0.8976 - val_loss: 0.1020 - val_f2_score: 0.8933\n",
      "Epoch 13/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0852 - f2_score: 0.8993 - val_loss: 0.0814 - val_f2_score: 0.8915\n",
      "Epoch 14/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0836 - f2_score: 0.9018 - val_loss: 0.1293 - val_f2_score: 0.8921\n",
      "Epoch 15/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0831 - f2_score: 0.9016 - val_loss: 0.0844 - val_f2_score: 0.8946\n",
      "Epoch 16/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0820 - f2_score: 0.9035 - val_loss: 0.0668 - val_f2_score: 0.8916\n",
      "Epoch 17/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0801 - f2_score: 0.9045 - val_loss: 0.1779 - val_f2_score: 0.8928\n",
      "Epoch 18/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0790 - f2_score: 0.9066 - val_loss: 0.0819 - val_f2_score: 0.8874\n",
      "Epoch 19/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0778 - f2_score: 0.9077 - val_loss: 0.0938 - val_f2_score: 0.8940\n",
      "Epoch 20/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0770 - f2_score: 0.9085 - val_loss: 0.1095 - val_f2_score: 0.8945\n",
      "Epoch 21/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0752 - f2_score: 0.9122 - val_loss: 0.1131 - val_f2_score: 0.8958\n",
      "Epoch 22/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0739 - f2_score: 0.9129 - val_loss: 0.0884 - val_f2_score: 0.8947\n",
      "Epoch 23/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0726 - f2_score: 0.9149 - val_loss: 0.1050 - val_f2_score: 0.8920\n",
      "Epoch 24/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0713 - f2_score: 0.9161 - val_loss: 0.0960 - val_f2_score: 0.8922\n",
      "Epoch 25/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0691 - f2_score: 0.9187 - val_loss: 0.0607 - val_f2_score: 0.8924\n",
      "Found 32383 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n",
      "Found 61191 validated image filenames belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 194s 767ms/step - loss: 0.1764 - f2_score: 0.8103 - val_loss: 0.1074 - val_f2_score: 0.8384\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.1160 - f2_score: 0.8632 - val_loss: 0.1068 - val_f2_score: 0.8601\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.1082 - f2_score: 0.8731 - val_loss: 0.0960 - val_f2_score: 0.8756\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.1034 - f2_score: 0.8787 - val_loss: 0.0865 - val_f2_score: 0.8778\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 183s 724ms/step - loss: 0.0996 - f2_score: 0.8834 - val_loss: 0.0837 - val_f2_score: 0.8861\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 183s 721ms/step - loss: 0.0977 - f2_score: 0.8854 - val_loss: 0.1006 - val_f2_score: 0.8794\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0953 - f2_score: 0.8882 - val_loss: 0.1168 - val_f2_score: 0.8825\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0934 - f2_score: 0.8905 - val_loss: 0.1065 - val_f2_score: 0.8888\n",
      "Epoch 9/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0919 - f2_score: 0.8921 - val_loss: 0.0623 - val_f2_score: 0.8914\n",
      "Epoch 10/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0895 - f2_score: 0.8952 - val_loss: 0.1477 - val_f2_score: 0.8875\n",
      "Epoch 11/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0884 - f2_score: 0.8959 - val_loss: 0.1194 - val_f2_score: 0.8894\n",
      "Epoch 12/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0870 - f2_score: 0.8975 - val_loss: 0.0917 - val_f2_score: 0.8877\n",
      "Epoch 13/25\n",
      "253/253 [==============================] - 183s 723ms/step - loss: 0.0858 - f2_score: 0.8985 - val_loss: 0.0811 - val_f2_score: 0.8962\n",
      "Epoch 14/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0840 - f2_score: 0.9021 - val_loss: 0.1162 - val_f2_score: 0.8876\n",
      "Epoch 15/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0825 - f2_score: 0.9025 - val_loss: 0.0459 - val_f2_score: 0.8879\n",
      "Epoch 16/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0809 - f2_score: 0.9041 - val_loss: 0.0701 - val_f2_score: 0.8903\n",
      "Epoch 17/25\n",
      "253/253 [==============================] - 181s 716ms/step - loss: 0.0801 - f2_score: 0.9055 - val_loss: 0.1230 - val_f2_score: 0.8916\n",
      "Epoch 18/25\n",
      "253/253 [==============================] - 181s 717ms/step - loss: 0.0779 - f2_score: 0.9086 - val_loss: 0.1334 - val_f2_score: 0.8885\n",
      "Epoch 19/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0774 - f2_score: 0.9087 - val_loss: 0.0815 - val_f2_score: 0.8931\n",
      "Epoch 20/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0757 - f2_score: 0.9100 - val_loss: 0.1084 - val_f2_score: 0.8920\n",
      "Epoch 21/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0742 - f2_score: 0.9126 - val_loss: 0.0816 - val_f2_score: 0.8913\n",
      "Epoch 22/25\n",
      "253/253 [==============================] - 183s 721ms/step - loss: 0.0729 - f2_score: 0.9148 - val_loss: 0.0538 - val_f2_score: 0.8885\n",
      "Epoch 23/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0719 - f2_score: 0.9153 - val_loss: 0.1413 - val_f2_score: 0.8905\n",
      "Epoch 24/25\n",
      "253/253 [==============================] - 182s 718ms/step - loss: 0.0701 - f2_score: 0.9168 - val_loss: 0.0820 - val_f2_score: 0.8910\n",
      "Epoch 25/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0689 - f2_score: 0.9189 - val_loss: 0.1370 - val_f2_score: 0.8891\n",
      "Found 32384 validated image filenames belonging to 17 classes.\n",
      "Found 8095 validated image filenames belonging to 17 classes.\n",
      "Found 61191 validated image filenames belonging to 17 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 194s 768ms/step - loss: 0.1847 - f2_score: 0.7981 - val_loss: 0.1250 - val_f2_score: 0.8423\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.1159 - f2_score: 0.8646 - val_loss: 0.1181 - val_f2_score: 0.8691\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 183s 723ms/step - loss: 0.1083 - f2_score: 0.8715 - val_loss: 0.1261 - val_f2_score: 0.8738\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.1034 - f2_score: 0.8776 - val_loss: 0.0534 - val_f2_score: 0.8876\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 183s 723ms/step - loss: 0.0998 - f2_score: 0.8819 - val_loss: 0.0964 - val_f2_score: 0.8887\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0981 - f2_score: 0.8844 - val_loss: 0.0926 - val_f2_score: 0.8922\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0952 - f2_score: 0.8872 - val_loss: 0.0913 - val_f2_score: 0.8856\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0928 - f2_score: 0.8901 - val_loss: 0.0528 - val_f2_score: 0.8838\n",
      "Epoch 9/25\n",
      "253/253 [==============================] - 183s 721ms/step - loss: 0.0914 - f2_score: 0.8920 - val_loss: 0.0613 - val_f2_score: 0.8892\n",
      "Epoch 10/25\n",
      "253/253 [==============================] - 182s 719ms/step - loss: 0.0897 - f2_score: 0.8942 - val_loss: 0.0862 - val_f2_score: 0.8892\n",
      "Epoch 11/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0888 - f2_score: 0.8958 - val_loss: 0.1211 - val_f2_score: 0.8900\n",
      "Epoch 12/25\n",
      "253/253 [==============================] - 183s 723ms/step - loss: 0.0867 - f2_score: 0.8984 - val_loss: 0.0983 - val_f2_score: 0.8927\n",
      "Epoch 13/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0857 - f2_score: 0.8988 - val_loss: 0.1257 - val_f2_score: 0.8906\n",
      "Epoch 14/25\n",
      "253/253 [==============================] - 183s 721ms/step - loss: 0.0836 - f2_score: 0.9014 - val_loss: 0.1248 - val_f2_score: 0.8904\n",
      "Epoch 15/25\n",
      "253/253 [==============================] - 183s 723ms/step - loss: 0.0834 - f2_score: 0.9014 - val_loss: 0.0911 - val_f2_score: 0.8913\n",
      "Epoch 16/25\n",
      "253/253 [==============================] - 183s 721ms/step - loss: 0.0816 - f2_score: 0.9036 - val_loss: 0.1813 - val_f2_score: 0.8921\n",
      "Epoch 17/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0805 - f2_score: 0.9039 - val_loss: 0.0823 - val_f2_score: 0.8949\n",
      "Epoch 18/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0784 - f2_score: 0.9067 - val_loss: 0.0711 - val_f2_score: 0.8918\n",
      "Epoch 19/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0783 - f2_score: 0.9083 - val_loss: 0.1014 - val_f2_score: 0.8916\n",
      "Epoch 20/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0759 - f2_score: 0.9105 - val_loss: 0.0785 - val_f2_score: 0.8924\n",
      "Epoch 21/25\n",
      "253/253 [==============================] - 183s 724ms/step - loss: 0.0752 - f2_score: 0.9105 - val_loss: 0.1212 - val_f2_score: 0.8886\n",
      "Epoch 22/25\n",
      "253/253 [==============================] - 182s 721ms/step - loss: 0.0732 - f2_score: 0.9139 - val_loss: 0.0796 - val_f2_score: 0.8965\n",
      "Epoch 23/25\n",
      "253/253 [==============================] - 183s 722ms/step - loss: 0.0721 - f2_score: 0.9149 - val_loss: 0.1124 - val_f2_score: 0.8978\n",
      "Epoch 24/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0706 - f2_score: 0.9165 - val_loss: 0.0952 - val_f2_score: 0.8957\n",
      "Epoch 25/25\n",
      "253/253 [==============================] - 182s 720ms/step - loss: 0.0691 - f2_score: 0.9186 - val_loss: 0.1861 - val_f2_score: 0.8926\n"
     ]
    }
   ],
   "source": [
    "#Run the model  with k-fold cross validation:\n",
    "\n",
    "num_fold = 0\n",
    "EPOCHS = 25\n",
    "\n",
    "y_test = []\n",
    "\n",
    "folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=1).split(X_train_files, y_train)\n",
    "\n",
    "for train_index, val_index in folds:\n",
    "    X_train_files_fold = X_train_files[train_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    X_val_files_fold = X_train_files[val_index]\n",
    "    y_val_fold = np.array(y_train[val_index])\n",
    "    \n",
    "    train_df = pd.DataFrame(list(zip(X_train_files_fold, y_train_fold)), columns = ['image_name', 'tags'])\n",
    "    val_df = pd.DataFrame(list(zip(X_val_files_fold, y_val_fold)), columns = ['image_name', 'tags'])\n",
    "    \n",
    "    train_df['tags'] = train_df['tags'].apply(lambda x: x.split(' '))\n",
    "    val_df['tags'] = val_df['tags'].apply(lambda x: x.split(' '))\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        directory=TRAIN_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        directory=TRAIN_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        df_test,\n",
    "        directory=TEST_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    model_path_of_fold = os.path.join('', 'weights_of_fold_' + str(num_fold) + '.h5')\n",
    "    \n",
    "    clear_session()\n",
    "    model = create_model()\n",
    "    \n",
    "    adam = Adam(learning_rate=LR)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f2_score])\n",
    "    \n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path_of_fold, monitor='val_f2_score', save_best_only=True, mode='max'),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001)\n",
    "    ]\n",
    "    \n",
    "    model.fit_generator(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks,\n",
    "                       workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "\n",
    "    model.load_weights(model_path_of_fold)\n",
    "\n",
    "    p_test = model.predict_generator(test_generator, workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "    y_test.append(p_test)\n",
    "    num_fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>haze</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>primary</th>\n",
       "      <th>road</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.055895</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.988933</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.014499</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.117781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.560670</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.034128</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.881734</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.194397</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.888016</td>\n",
       "      <td>0.851879</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.099323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agriculture  artisinal_mine  bare_ground  blooming  blow_down     clear  \\\n",
       "0     0.003196        0.000027     0.000427  0.055895   0.000356  0.988933   \n",
       "1     0.003101        0.000001     0.000227  0.019377   0.001453  0.999561   \n",
       "2     0.022939        0.000007     0.000130  0.000044   0.001032  0.000058   \n",
       "3     0.560670        0.000129     0.005879  0.034128   0.005307  0.881734   \n",
       "4     0.006003        0.000019     0.000071  0.000056   0.000059  0.000107   \n",
       "\n",
       "     cloudy  conventional_mine  cultivation  habitation      haze  \\\n",
       "0  0.000056           0.000017     0.001600    0.000791  0.006435   \n",
       "1  0.000014           0.000004     0.000522    0.014499  0.000008   \n",
       "2  0.000005           0.000101     0.003081    0.000675  0.000019   \n",
       "3  0.000034           0.000040     0.577957    0.007550  0.003961   \n",
       "4  0.194397           0.000157     0.000552    0.000254  0.000105   \n",
       "\n",
       "   partly_cloudy   primary      road  selective_logging  slash_burn     water  \n",
       "0       0.000629  0.999974  0.001654           0.006827    0.000172  0.002346  \n",
       "1       0.000994  0.999970  0.002443           0.001804    0.000125  0.000142  \n",
       "2       0.999784  0.999994  0.016098           0.000674    0.000033  0.117781  \n",
       "3       0.133713  0.999926  0.007581           0.013681    0.002748  0.006211  \n",
       "4       0.888016  0.851879  0.002610           0.000177    0.000045  0.099323  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average out the results obtained from k folds of cross validation\n",
    "result_haze = np.array(y_test[0])\n",
    "for i in range(1, NFOLDS):\n",
    "    result_haze += np.array(y_test[i])\n",
    "result_haze /= NFOLDS\n",
    "result_haze = pd.DataFrame(result_haze, columns = labels)\n",
    "result_haze.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling the result_new df\n",
    "import pickle\n",
    "pickle1_out = open('result_mb_haze.pickle', 'wb')\n",
    "pickle.dump(result_haze, pickle1_out, protocol=4)\n",
    "pickle1_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create prediction flag and create a submission file for kaggle submission\n",
    "preds = []\n",
    "for i in range(result_haze.shape[0]):\n",
    "    a = result_haze.ix[[i]]\n",
    "    a = a.apply(lambda x: x > THRES, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n",
    "    \n",
    "df_test['tags'] = preds\n",
    "df_test['image_name'] = df_test['image_name'].astype(str).str.slice(stop=-4)\n",
    "df_test.to_csv('submit_haze.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
